{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "from cityscape import CityscapeConfig, CityscapeDataset\n",
    "from models import ResNet, FlowNet, MaskRCNN, Warp, Decision\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/data/cityscapes_dataset/cityscape'\n",
    "config = CityscapeConfig()\n",
    "config.IMAGE_SHAPE = [1024, 1024, 6]\n",
    "config.Flow =True\n",
    "config.POST_NMS_ROIS_INFERENCE = 500\n",
    "#config.display()\n",
    "\n",
    "# Validation dataset\n",
    "offset = 20\n",
    "dataset_val = CityscapeDataset()\n",
    "dataset_val.load_cityscape(data_dir, \"val\", offset)\n",
    "dataset_val.prepare()\n",
    "\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
    "for i, info in enumerate(dataset_val.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(config=config)\n",
    "flownet = FlowNet(config=config)\n",
    "maskrcnn = MaskRCNN(config=config)\n",
    "warp = Warp(config=config)\n",
    "decision = Decision()\n",
    "\n",
    "model_path = \"/home/susean/Mask_RCNN/logs/mask_rcnn_cityscapes_0040.h5\"\n",
    "resnet.load_weights(model_path, by_name=True)\n",
    "flownet.load_weights(model_path, by_name=True)\n",
    "maskrcnn.load_weights(model_path, by_name=True)\n",
    "decision.load_weights(\"/home/susean/Mask_RCNN/logs/deciosion_0181_2.59.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "APs = []\n",
    "threshold = 85\n",
    "seg_step = 0\n",
    "flow_step = 0\n",
    "score = 0\n",
    "for image_id in range(len(dataset_val.image_ids)):\n",
    "     # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "    current = np.expand_dims(image[:,:,3:], 0)\n",
    "    image_metas = np.expand_dims(image_meta, 0)\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    if image_id % offset != 0:\n",
    "        images = np.concatenate([current, key], 3)\n",
    "        flow, flow_feature = flownet.keras_model.predict(images)\n",
    "        score = decision.keras_model.predict(flow_feature)\n",
    "\n",
    "    if score < threshold or image_id % offset == 0:\n",
    "        seg_step += 1\n",
    "        key_P2, key_P3, key_P4, key_P5, key_P6 = resnet.keras_model.predict(current)\n",
    "\n",
    "        key = current\n",
    "        P2, P3, P4, P5, P6 = key_P2, key_P3, key_P4, key_P5, key_P6\n",
    "    else:\n",
    "        flow_step += 1\n",
    "        P2, P3, P4, P5, P6 = warp.predict([key_P2, key_P3, key_P4, key_P5, key_P6, flow])\n",
    "\n",
    "    inputs=[image_metas, P2, P3, P4, P5, P6]\n",
    "    result = maskrcnn.detect_molded(inputs)\n",
    "    #data_time = time.time() - start_time\n",
    "    #print(\"times {:.6f}\".format(data_time))\n",
    "    #print(score)\n",
    "    \n",
    "    if np.sum(result[\"scores\"]) == 0:\n",
    "        print(\"{} Fasle\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    # Compute AP\n",
    "    if (image_id+1) % offset == 0:\n",
    "        AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                        result[\"rois\"], result[\"class_ids\"], result[\"scores\"], result['masks'])\n",
    "        #AP = utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "        #               result[\"rois\"], result[\"class_ids\"], result[\"scores\"], result['masks'], verbose=0)\n",
    "        APs.append(AP)\n",
    "        print(\"step: {:3d}, mAP: {:.3f}\".format(image_id, np.mean(APs)))\n",
    "        \n",
    "print(\"step: {:3d}, mAP: {:.3f}\".format(image_id, np.mean(APs)))\n",
    "print(\"segmentation steps:\", seg_step, \"flow steps:\", flow_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
